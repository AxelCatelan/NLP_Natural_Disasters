{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b254bd",
   "metadata": {},
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1449ee55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:53:57.543759Z",
     "start_time": "2022-04-12T12:53:57.483079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54750a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:53:57.697295Z",
     "start_time": "2022-04-12T12:53:57.666384Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb71e76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:53:58.060112Z",
     "start_time": "2022-04-12T12:53:58.033701Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d2cdd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:53:58.679337Z",
     "start_time": "2022-04-12T12:53:58.649830Z"
    }
   },
   "outputs": [],
   "source": [
    "from NLP_Natural_Disasters.data import get_data, clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb2e6e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:53:59.036583Z",
     "start_time": "2022-04-12T12:53:59.009640Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, 'display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c72f85b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:54:01.766053Z",
     "start_time": "2022-04-12T12:54:00.146749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resident asked shelter place officer evacuation shelter place order expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfire evacuation order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>got sent photo alaska smoke wildfire school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           text  \\\n",
       "0                                    deed reason earthquake may allah forgive u   \n",
       "1                                                    forest fire near la canada   \n",
       "2  resident asked shelter place officer evacuation shelter place order expected   \n",
       "3                           people receive wildfire evacuation order california   \n",
       "4                                   got sent photo alaska smoke wildfire school   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_data(get_data()).drop(columns=['id'])\n",
    "df = df[df['text'] != '']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44929cdb",
   "metadata": {},
   "source": [
    "# Simple Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ebd5cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:54:01.798423Z",
     "start_time": "2022-04-12T12:54:01.767922Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f645d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:54:01.926708Z",
     "start_time": "2022-04-12T12:54:01.799811Z"
    }
   },
   "outputs": [],
   "source": [
    "# This initializes a Keras utilities that does all the tokenization for you\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# The tokenization learns a dictionnary that maps a token (integer) to each word\n",
    "# It can be done only on the train set - we are not supposed to know the test set !\n",
    "# This tokenization also lower your words, apply some filters, and so on - you can check the doc if you want\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_token = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "668643c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:54:03.194020Z",
     "start_time": "2022-04-12T12:54:03.154305Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9330e41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:54:03.840923Z",
     "start_time": "2022-04-12T12:54:03.810159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 110., 4796., 1015., ...,    0.,    0.,    0.],\n",
       "       [ 732.,  333.,  282., ...,    0.,    0.,    0.],\n",
       "       [3262.,  733.,  826., ...,    0.,    0.,    0.],\n",
       "       ...,\n",
       "       [  46.,   41., 1607., ...,    0.,    0.,    0.],\n",
       "       [ 115.,  820.,  371., ...,    0.,    0.,    0.],\n",
       "       [ 789., 2759., 1456., ...,    0.,    0.,    0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf81995",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69aa69e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:54:07.203489Z",
     "start_time": "2022-04-12T12:54:07.169785Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cece77d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:54:09.223952Z",
     "start_time": "2022-04-12T12:54:08.506065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 14:54:08.692711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-04-12 14:54:08.694369: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-12 14:54:08.694426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-12 14:54:08.694468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-12 14:54:08.694507: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-04-12 14:54:08.694574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-04-12 14:54:08.694615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-12 14:54:08.694697: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-04-12 14:54:08.694739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-04-12 14:54:08.694746: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-04-12 14:54:08.695709: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 50)          273100    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 20)                5680      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                210       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 279,001\n",
      "Trainable params: 279,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Params dimension vectors\n",
    "model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size+1, output_dim=50 , mask_zero=True),\n",
    "    layers.LSTM(20),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "547bc6b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T12:54:31.903242Z",
     "start_time": "2022-04-12T12:54:11.697955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "267/267 [==============================] - 6s 12ms/step - loss: 0.5817 - acc: 0.7162 - val_loss: 0.5008 - val_acc: 0.7770\n",
      "Epoch 2/20\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.3933 - acc: 0.8421 - val_loss: 0.4840 - val_acc: 0.7923\n",
      "Epoch 3/20\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.3412 - acc: 0.8623 - val_loss: 0.4857 - val_acc: 0.7879\n",
      "Epoch 4/20\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.3125 - acc: 0.8767 - val_loss: 0.4877 - val_acc: 0.7852\n",
      "Epoch 5/20\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.2963 - acc: 0.8849 - val_loss: 0.5094 - val_acc: 0.7847\n",
      "Epoch 6/20\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.2793 - acc: 0.8938 - val_loss: 0.5122 - val_acc: 0.7825\n",
      "Epoch 7/20\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.2665 - acc: 0.8997 - val_loss: 0.5242 - val_acc: 0.7819\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=5)\n",
    "history = model.fit(X_train_pad, y_train, validation_split=0.3, batch_size=16, epochs=20, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6ae2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:19:50.119799Z",
     "start_time": "2022-04-12T11:19:49.199176Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_pad, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9791d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:19:50.146258Z",
     "start_time": "2022-04-12T11:19:50.121307Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75056659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:20:48.105316Z",
     "start_time": "2022-04-12T11:20:47.963602Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1241d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-12T11:19:55.454068Z",
     "start_time": "2022-04-12T11:19:55.416742Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e44738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
