{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5f3df",
   "metadata": {
    "id": "86d5f3df"
   },
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2239a2",
   "metadata": {
    "id": "6e2239a2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7328928",
   "metadata": {
    "id": "d7328928"
   },
   "outputs": [],
   "source": [
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "iHhWuiSSX_WP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHhWuiSSX_WP",
    "outputId": "e35300f6-2771-4681-bb24-c223a1904d8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow\n",
      "  Downloading bert_tensorflow-1.0.4-py2.py3-none-any.whl (64 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |█████                           | 10 kB 21.0 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 20 kB 14.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 30 kB 10.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 40 kB 8.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 51 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 61 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 64 kB 1.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow) (1.15.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "JGcC7xDCXhy_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGcC7xDCXhy_",
    "outputId": "6b29229a-8162-463e-d84f-87b63e5bef94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-for-tf2\n",
      "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |████████                        | 10 kB 26.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 20 kB 12.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 30 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 40 kB 4.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 41 kB 114 kB/s \n",
      "\u001b[?25hCollecting py-params>=0.9.6\n",
      "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
      "Collecting params-flow>=0.8.0\n",
      "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.63.0)\n",
      "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30535 sha256=280e8e08ae054b2d4dcdeda8f686376bd1d9618dd437f37b70716a0b8830fd4e\n",
      "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=48ba393565c3261869164bd54d78b4ed60716fe37982f1eee6a79fc5a54d3ec7\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=c03915c3930c30fa297ef3645cc9ad28054db01f4121a1abed027e62c4d1ffbc\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
      "Successfully built bert-for-tf2 params-flow py-params\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n"
     ]
    }
   ],
   "source": [
    "pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "I1IHHoTqYWMB",
   "metadata": {
    "id": "I1IHHoTqYWMB"
   },
   "outputs": [],
   "source": [
    "from bert import bert_tokenization\n",
    "BertTokenizer = bert_tokenization.FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "KxOdwhxqXmRL",
   "metadata": {
    "id": "KxOdwhxqXmRL"
   },
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = BertTokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "UpgfbwZJYmQk",
   "metadata": {
    "id": "UpgfbwZJYmQk"
   },
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(clf_output)\n",
    "    \n",
    "    # instantiate model\n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "\n",
    "    # compile\n",
    "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WolINpq5ZVE4",
   "metadata": {
    "id": "WolINpq5ZVE4"
   },
   "source": [
    " Loading BERT from the Tensorflow Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "G75vpZa_Y9zU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G75vpZa_Y9zU",
    "outputId": "3521c837-06ce-42d5-d381-9dc3125ddad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 s, sys: 6.09 s, total: 35.4 s\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JsUiKZt2aSTG",
   "metadata": {
    "id": "JsUiKZt2aSTG"
   },
   "source": [
    " Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nLSFIo8tZ620",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "nLSFIo8tZ620",
    "outputId": "6093d053-b7b2-45be-82f1-cb57393c34e5"
   },
   "outputs": [],
   "source": [
    "from NLP_Natural_Disasters.data import get_data, clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eShf2NgfaWsr",
   "metadata": {
    "id": "eShf2NgfaWsr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>two giant crane holding bridge collapse nearby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>ariaahrary thetawniest control wild fire calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>utckm volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>police investigating ebike collided car little...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>latest home razed northern california wildfire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  target\n",
       "0         1         deed reason earthquake may allah forgive u       1\n",
       "1         4              forest fire near la ronge sask canada       1\n",
       "2         5  resident asked shelter place notified officer ...       1\n",
       "3         6  people receive wildfire evacuation order calif...       1\n",
       "4         7  got sent photo ruby alaska smoke wildfire pour...       1\n",
       "...     ...                                                ...     ...\n",
       "7608  10869  two giant crane holding bridge collapse nearby...       1\n",
       "7609  10870  ariaahrary thetawniest control wild fire calif...       1\n",
       "7610  10871                               utckm volcano hawaii       1\n",
       "7611  10872  police investigating ebike collided car little...       1\n",
       "7612  10873  latest home razed northern california wildfire...       1\n",
       "\n",
       "[7613 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data(get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a37f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "diana_model_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
