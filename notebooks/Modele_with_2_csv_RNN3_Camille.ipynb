{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modele_with_2_csv_RNN3_Camille.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E3NHcOhaMWY3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "max_long = 25"
      ],
      "metadata": {
        "id": "04LHeI1KMgDg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlfgqbAtMj_R",
        "outputId": "f81a8a6d-8091-4a6c-846c-d82bfb5e8409"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive')"
      ],
      "metadata": {
        "id": "r_b4a-wBMqWT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1upxosMNMv3e",
        "outputId": "ad565ada-d42f-4526-e391-e566c5eabdc5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 24.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import data\n",
        "data.get_data, data.clean_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXK0lbrpMx2l",
        "outputId": "48839cfd-5ce5-4935-887c-d2bfbfb5bf69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<function data.get_data>, <function data.clean_data>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import token_glove\n",
        "token_glove.create_list, token_glove.token_ize, token_glove.voc_token, token_glove.dict_token, token_glove.token_tweet, token_glove.glove_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq9WBI45M0i8",
        "outputId": "9c0b0f4a-79af-4850-cc4d-159a3469dfb0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<function token_glove.create_list>,\n",
              " <function token_glove.token_ize>,\n",
              " <function token_glove.voc_token>,\n",
              " <function token_glove.dict_token>,\n",
              " <function token_glove.token_tweet>,\n",
              " <function token_glove.glove_vector>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import metrics\n",
        "metrics.recall_m, metrics.precision_m, metrics.f1_m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yywkD2XOM3OE",
        "outputId": "8e483bd7-ab2a-43ee-a39b-0278e0d4e4d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<function metrics.recall_m>,\n",
              " <function metrics.precision_m>,\n",
              " <function metrics.f1_m>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjETzcPbM5M1",
        "outputId": "bcbe6002-1df3-41cc-d43b-9022de286053"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.get_data()\n",
        "cleaned_df = data.clean_data(df)"
      ],
      "metadata": {
        "id": "lToUcBtUM7BW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = token_glove.create_list(cleaned_df['text'])\n",
        "token = token_glove.token_ize(text)\n",
        "X = token_glove.token_tweet(text, token)"
      ],
      "metadata": {
        "id": "9HhWN4-6M9Za"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vector_matrix = token_glove.glove_vector(token)"
      ],
      "metadata": {
        "id": "Ecw82wPcNAH7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, Activation, Dropout, LSTM\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "m7taHkuzNCQd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = token_glove.voc_token(token)\n",
        "vec_size = 200"
      ],
      "metadata": {
        "id": "2f0zN-_ANuJL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = cleaned_df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size= 0.3, stratify = y)"
      ],
      "metadata": {
        "id": "JAJkAKMpNyte"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = Sequential()\n",
        "\n",
        "es = EarlyStopping(patience=5,restore_best_weights= True)\n",
        "\n",
        "model6.add(Embedding(vocab_size, vec_size, input_length=max_long, weights = [word_vector_matrix], trainable = True))\n",
        "model6.add(Dense(16, activation='relu'))\n",
        "model6.add(Dense(500, activation='relu'))\n",
        "model6.add(Dense(500, activation='relu'))\n",
        "model6.add(Dense(16, activation='relu'))\n",
        "model6.add(Dense(1, activation='sigmoid'))\n",
        "model6.compile(loss='binary_crossentropy',optimizer=RMSprop(learning_rate = 0.0001),metrics=[metrics.f1_m])\n",
        "history3 = model6.fit(X_train, y_train, batch_size=16, epochs = 400, validation_data = (X_test, y_test), callbacks = [es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTCfRBydREQN",
        "outputId": "1eb7874f-19e9-4313-9486-2bec5fb318d2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "333/333 [==============================] - 19s 51ms/step - loss: 0.6750 - f1_m: 1.0064 - val_loss: 0.6670 - val_f1_m: 1.1025\n",
            "Epoch 2/400\n",
            "333/333 [==============================] - 17s 51ms/step - loss: 0.6647 - f1_m: 1.1111 - val_loss: 0.6602 - val_f1_m: 1.1551\n",
            "Epoch 3/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6595 - f1_m: 1.1503 - val_loss: 0.6573 - val_f1_m: 1.1832\n",
            "Epoch 4/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6565 - f1_m: 1.1771 - val_loss: 0.6550 - val_f1_m: 1.1690\n",
            "Epoch 5/400\n",
            "333/333 [==============================] - 19s 56ms/step - loss: 0.6541 - f1_m: 1.1829 - val_loss: 0.6551 - val_f1_m: 1.2296\n",
            "Epoch 6/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6519 - f1_m: 1.1990 - val_loss: 0.6515 - val_f1_m: 1.2071\n",
            "Epoch 7/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6493 - f1_m: 1.2038 - val_loss: 0.6525 - val_f1_m: 1.1568\n",
            "Epoch 8/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6482 - f1_m: 1.2097 - val_loss: 0.6498 - val_f1_m: 1.2220\n",
            "Epoch 9/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6466 - f1_m: 1.2234 - val_loss: 0.6493 - val_f1_m: 1.1768\n",
            "Epoch 10/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6450 - f1_m: 1.2161 - val_loss: 0.6484 - val_f1_m: 1.1998\n",
            "Epoch 11/400\n",
            "333/333 [==============================] - 17s 50ms/step - loss: 0.6440 - f1_m: 1.2280 - val_loss: 0.6474 - val_f1_m: 1.2093\n",
            "Epoch 12/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6427 - f1_m: 1.2278 - val_loss: 0.6469 - val_f1_m: 1.2028\n",
            "Epoch 13/400\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 0.6417 - f1_m: 1.2367 - val_loss: 0.6466 - val_f1_m: 1.2020\n",
            "Epoch 14/400\n",
            "333/333 [==============================] - 17s 51ms/step - loss: 0.6408 - f1_m: 1.2406 - val_loss: 0.6466 - val_f1_m: 1.2084\n",
            "Epoch 15/400\n",
            "333/333 [==============================] - 17s 50ms/step - loss: 0.6398 - f1_m: 1.2412 - val_loss: 0.6466 - val_f1_m: 1.2169\n",
            "Epoch 16/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6391 - f1_m: 1.2538 - val_loss: 0.6465 - val_f1_m: 1.2194\n",
            "Epoch 17/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6386 - f1_m: 1.2578 - val_loss: 0.6462 - val_f1_m: 1.2006\n",
            "Epoch 18/400\n",
            "333/333 [==============================] - 17s 50ms/step - loss: 0.6378 - f1_m: 1.2525 - val_loss: 0.6470 - val_f1_m: 1.2049\n",
            "Epoch 19/400\n",
            "333/333 [==============================] - 18s 55ms/step - loss: 0.6370 - f1_m: 1.2571 - val_loss: 0.6459 - val_f1_m: 1.1997\n",
            "Epoch 20/400\n",
            "333/333 [==============================] - 16s 49ms/step - loss: 0.6367 - f1_m: 1.2561 - val_loss: 0.6463 - val_f1_m: 1.2015\n",
            "Epoch 21/400\n",
            "333/333 [==============================] - 16s 47ms/step - loss: 0.6360 - f1_m: 1.2660 - val_loss: 0.6462 - val_f1_m: 1.2161\n",
            "Epoch 22/400\n",
            "333/333 [==============================] - 16s 47ms/step - loss: 0.6359 - f1_m: 1.2593 - val_loss: 0.6461 - val_f1_m: 1.2052\n",
            "Epoch 23/400\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 0.6351 - f1_m: 1.2682 - val_loss: 0.6476 - val_f1_m: 1.2210\n",
            "Epoch 24/400\n",
            "333/333 [==============================] - 16s 48ms/step - loss: 0.6345 - f1_m: 1.2659 - val_loss: 0.6509 - val_f1_m: 1.2549\n"
          ]
        }
      ]
    }
  ]
}